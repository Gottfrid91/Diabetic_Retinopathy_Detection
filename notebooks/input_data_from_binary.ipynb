{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is the sequential execution of the input data file to disect every step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Routine for decoding the digits-10 binary file format.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "# Process images of this size. Note that this differs from the original CIFAR\n",
    "# image size of 32 x 32. If one alters this number, then the entire model\n",
    "# architecture will change and any model would need to be retrained.\n",
    "IMAGE_SIZE = 24\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000 # was set from 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "# FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# # Basic model parameters.\n",
    "# #former batch size was 128\n",
    "# tf.app.flags.DEFINE_integer('batch_size', 1 ,\n",
    "#                             \"\"\"Number of images to process in a batch.\"\"\")\n",
    "# tf.app.flags.DEFINE_string('data_dir', './tmp/cifar10_data',\n",
    "#                            \"\"\"Path to the CIFAR-10 data directory.\"\"\")\n",
    "# tf.app.flags.DEFINE_boolean('use_fp16', False,\n",
    "#                             \"\"\"Train the model using fp16.\"\"\")\n",
    "# tf.app.flags.DEFINE_string('eval_data', 'test',\n",
    "#                  \"\"\"Either 'test' or 'train_eval'.\"\"\")\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "data_dir = './data_format_2/digits-10-batches-bin'\n",
    "\n",
    "use_fp16 = False\n",
    "\n",
    "eval_data = 'test'\n",
    "\n",
    "\n",
    "\n",
    "# Constants describing the training process.\n",
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "NUM_EPOCHS_PER_DECAY = 350.0      # Epochs after which learning rate decays.\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.1  # Learning rate decay factor.\n",
    "INITIAL_LEARNING_RATE = 0.1       # Initial learning rate.\n",
    "\n",
    "# If a model is trained with multiple GPUs, prefix all Op names with tower_name\n",
    "# to ifferentiate the operations. Note that this prefix is removed from the\n",
    "# names of the summaries when visualizing a model.\n",
    "TOWER_NAME = 'tower'\n",
    "\n",
    "DATA_URL = 'https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "                     for i in xrange(1, 5)]\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "# Dimensions of the images in the CIFAR-10 dataset.\n",
    "# See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "# input format.\n",
    "label_bytes = 1  # 2 for CIFAR-100\n",
    "height = 32\n",
    "width = 32\n",
    "depth = 3\n",
    "image_bytes = height * width * depth\n",
    "# Every record consists of a label followed by the image, with a\n",
    "# fixed number of bytes for each.\n",
    "record_bytes = label_bytes + image_bytes\n",
    "reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "\n",
    "\n",
    "# Read a record, getting filenames from the filename_queue.  No\n",
    "# header or footer in the CIFAR-10 format, so we leave header_bytes\n",
    "# and footer_bytes at their default of 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    key, value = reader.read(filename_queue)\n",
    "\n",
    "    # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "    record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "\n",
    "    # The first bytes represent the label, which we convert from uint8->int32.\n",
    "    # The remaining bytes after the label represent the image, which we reshape\n",
    "    # from [depth * height * width] to [depth, height, width].\n",
    "    #depth_major = tf.strided_slice(record_bytes, [1],[1 + image_bytes])\n",
    "    #label = tf.strided_slice(record_bytes, [0], [1])\n",
    "\n",
    "#     # Convert from [depth, height, width] to [height, width, depth].\n",
    "#     uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "    #print(sess.run(depth_major))\n",
    "    print(sess.run(record_bytes[0]))\n",
    "#     print(sess.run(depth_major)) # data/heart.csv:2\n",
    "#     print(sess.run(label)) # 144,0.01,4.41,28.61,Absent,55,28.87,2.06,63,1\n",
    "\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below two blocks contains code reading .mat (matlab) files into binary format for tensorflow\n",
    "\n",
    "the code uses scipy and numpy to read, reformat and save data into binary fixed length records used by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## generating the training batches\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from array import array\n",
    "\n",
    "input_file = '/home/olle/PycharmProjects/Diabetic_Retinopathy_Detection/data/train/train.zip.005'\n",
    "read_input = scipy.io.loadmat(input_file)\n",
    "j=0\n",
    "output_file = open('data_batch_%d.bin' % j, 'ab')\n",
    "\n",
    "#X = read_input['X'].reshape(32*32*3, read_input['X'].shape[3])\n",
    "\n",
    "for i in range(0, 64000):\n",
    "\n",
    "    # create new bin file\n",
    "    if i>0 and i % 12800 == 0:\n",
    "        output_file.close()\n",
    "        j=j+1\n",
    "        output_file = open('data_batch_%d.bin' % j, 'ab')\n",
    "\n",
    "    # Write to bin file\n",
    "    if read_input['y'][i] == 10:\n",
    "        read_input['y'][i] = 0\n",
    "    read_input['y'][i].astype('uint8').tofile(output_file)\n",
    "    read_input['X'][:,:,:,i].astype('uint32').tofile(output_file)\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## generating the training batches\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from array import array\n",
    "\n",
    "test_input = scipy.io.loadmat('data_format_2/test_32x32.mat')\n",
    "j=0\n",
    "output_testfile = open('test_batch.bin', 'ab')\n",
    "\n",
    "X_test = test_input['X'].reshape(test_input['X'].shape[3], 32*32*3)\n",
    "for i in range(0,26032):\n",
    "    \n",
    "    # Write to bin file\n",
    "    if test_input['y'][i] == 10:\n",
    "        test_input['y'][i] = 0\n",
    "    test_input['y'][i].astype('uint8').tofile(output_testfile)\n",
    "    X_test[i].astype('uint32').tofile(output_testfile)\n",
    "\n",
    "output_testfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use below code chunk\n",
    "below is a test script for input data up until batch ops. The idea is that the below script should implement \n",
    "1. file parsing, \n",
    "2. create a suitable reader (here fixed length but can be changed to TFrecord,\n",
    "3. decoder of data type into numeric values\n",
    "4. Then open a session that extract features and labels from data\n",
    "5. pre-processes the data\n",
    "6. within the session easily prints the values such that debugging can be made\n",
    "                             \n",
    "Finally the below steps can be inserted into the CIFAR turorial design priciples for loading data. The code extracts the numeric values into numpy format, the code can be easily extended to vizualize the numeric data as pictures again using e.g. Pillow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting parameters for lading data and shape parameters for preprocesing\n",
    "label_bytes = 1  # 2 for CIFAR-100\n",
    "height = 32\n",
    "width = 32\n",
    "depth = 3\n",
    "\n",
    "#might have to be made dynamic\n",
    "image_bytes = height * width * depth\n",
    "\n",
    "# Every record consists of a label followed by the image, with a\n",
    "# fixed number of bytes for each.\n",
    "record_bytes = label_bytes + image_bytes\n",
    "\n",
    "filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "                     for i in xrange(1, 5)]\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(filenames)\n",
    "reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "\n",
    "key, value = reader.read(filename_queue)\n",
    "record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    label = tf.cast(tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
    "\n",
    "    depth_major = tf.reshape(tf.strided_slice(record_bytes, [label_bytes], [label_bytes + image_bytes]),\n",
    "        [depth, height, width])\n",
    "\n",
    "    # Convert from [depth, height, width] to [height, width, depth].\n",
    "    uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "    reshaped_image = tf.cast(uint8image, tf.float32)\n",
    "\n",
    "    # Image processing for evaluation.\n",
    "    # Crop the central [height, width] of the image.\n",
    "    resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,\n",
    "                                                           height, width)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(resized_image)\n",
    "    \n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    label.set_shape([1])\n",
    "    \n",
    "    # minimum number elements in the queue after a dequeue, used to ensure\n",
    "    # that the samples are sufficiently mixed\n",
    "    \n",
    "    # I think 10 times the BATCH_SIZE is sufficient   \n",
    "    #checkpoint - see so image has required form\n",
    "    for i in range(0,100):\n",
    "        print(sess.run(record_bytes)[0]) # data/heart.csv:2\n",
    "    #print(sess.run(label)) # 144,0.01,4.41,28.61,Absent,55,28.87,2.06,63,1\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
